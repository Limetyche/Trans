{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-15T12:42:03.849927Z",
     "end_time": "2024-03-15T12:42:03.851435Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "class TrainSet(Dataset):\n",
    "    def __init__(self):\n",
    "        super(TrainSet, self).__init__()\n",
    "        # self.raw_data, self.entity_dic, self.relation_dic = self.load_texd()\n",
    "        self.raw_data, self.entity_to_index, self.relation_to_index = self.load_text()\n",
    "        self.entity_num, self.relation_num = len(self.entity_to_index), len(self.relation_to_index)\n",
    "        self.triple_num = self.raw_data.shape[0]\n",
    "        print(f'Train set: {self.entity_num} entities, {self.relation_num} relations, {self.triple_num} triplets.')\n",
    "        self.pos_data = self.convert_word_to_index(self.raw_data)\n",
    "        self.related_dic = self.get_related_entity()\n",
    "        # print(self.related_dic[0], self.related_dic[479])\n",
    "        self.neg_data = self.generate_neg()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.triple_num\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return [self.pos_data[item], self.neg_data[item]]\n",
    "\n",
    "    def load_text(self):\n",
    "        raw_data = pd.read_csv('/kg/transe/fb15k/freebase_mtr100_mte100-train.txt', sep='\\t', header=None,\n",
    "                               names=['head', 'relation', 'tail'],\n",
    "                               keep_default_na=False, encoding='utf-8')\n",
    "        raw_data = raw_data.applymap(lambda x: x.strip())\n",
    "        head_count = Counter(raw_data['head'])\n",
    "        tail_count = Counter(raw_data['tail'])\n",
    "        relation_count = Counter(raw_data['relation'])\n",
    "        entity_list = list((head_count + tail_count).keys())\n",
    "        relation_list = list(relation_count.keys())\n",
    "        entity_dic = dict([(word, idx) for idx, word in enumerate(entity_list)])\n",
    "        relation_dic = dict([(word, idx) for idx, word in enumerate(relation_list)])\n",
    "        return raw_data.values, entity_dic, relation_dic\n",
    "\n",
    "    def convert_word_to_index(self, data):\n",
    "        index_list = np.array([\n",
    "            [self.entity_to_index[triple[0]], self.relation_to_index[triple[1]], self.entity_to_index[triple[2]]] for\n",
    "            triple in data])\n",
    "        return index_list\n",
    "\n",
    "    def generate_neg(self):\n",
    "        \"\"\"\n",
    "        generate negative sampling\n",
    "        :return: same shape as positive sampling\n",
    "        \"\"\"\n",
    "        neg_candidates, i = [], 0\n",
    "        neg_data = []\n",
    "        population = list(range(self.entity_num))\n",
    "        for idx, triple in enumerate(self.pos_data):\n",
    "            while True:\n",
    "                if i == len(neg_candidates):\n",
    "                    i = 0\n",
    "                    neg_candidates = random.choices(population=population, k=int(1e4))\n",
    "                neg, i = neg_candidates[i], i + 1\n",
    "                if random.randint(0, 1) == 0:\n",
    "                    # replace head\n",
    "                    if neg not in self.related_dic[triple[2]]:\n",
    "                        neg_data.append([neg, triple[1], triple[2]])\n",
    "                        break\n",
    "                else:\n",
    "                    # replace tail\n",
    "                    if neg not in self.related_dic[triple[0]]:\n",
    "                        neg_data.append([triple[0], triple[1], neg])\n",
    "                        break\n",
    "\n",
    "        return np.array(neg_data)\n",
    "\n",
    "    def get_related_entity(self):\n",
    "        \"\"\"\n",
    "        get related entities\n",
    "        :return: {entity_id: {related_entity_id_1, related_entity_id_2...}}\n",
    "        \"\"\"\n",
    "        related_dic = dict()\n",
    "        for triple in self.pos_data:\n",
    "            if related_dic.get(triple[0]) is None:\n",
    "                related_dic[triple[0]] = {triple[2]}\n",
    "            else:\n",
    "                related_dic[triple[0]].add(triple[2])\n",
    "            if related_dic.get(triple[2]) is None:\n",
    "                related_dic[triple[2]] = {triple[0]}\n",
    "            else:\n",
    "                related_dic[triple[2]].add(triple[0])\n",
    "        return related_dic\n",
    "\n",
    "\n",
    "class TestSet(Dataset):\n",
    "    def __init__(self):\n",
    "        super(TestSet, self).__init__()\n",
    "        self.raw_data = self.load_text()\n",
    "        self.data = self.raw_data\n",
    "        print(f\"Test set: {self.raw_data.shape[0]} triplets\")\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def load_text(self):\n",
    "        raw_data = pd.read_csv('/kg/transe/fb15k/freebase_mtr100_mte100-test.txt', sep='\\t', header=None,\n",
    "                               names=['head', 'relation', 'tail'],\n",
    "                               keep_default_na=False, encoding='utf-8')\n",
    "        raw_data = raw_data.applymap(lambda x: x.strip())\n",
    "        return raw_data.values\n",
    "\n",
    "    def convert_word_to_index(self, entity_to_index, relation_to_index, data):\n",
    "        index_list = np.array(\n",
    "            [[entity_to_index[triple[0]], relation_to_index[triple[1]], entity_to_index[triple[2]]] for triple in data])\n",
    "        self.data = index_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-15T12:42:03.909432Z",
     "end_time": "2024-03-15T12:42:03.938293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "    def __init__(self, ent_num, rel_num, device, dim=50, d_norn=2, margin=1):\n",
    "        '''\n",
    "        :param ent_num: entity_num\n",
    "        :param rel_num: relation_num\n",
    "        :param device: cuda_device\n",
    "        :param dim: dim = 50\n",
    "        :param d_norn: d_norm = 2\n",
    "        :param margin: margin hyperparameter\n",
    "        '''\n",
    "\n",
    "        super().__init__()\n",
    "        self.ent_num = ent_num\n",
    "        self.rel_num = rel_num\n",
    "\n",
    "        self.device = device\n",
    "        self.dim = dim\n",
    "        self.d_norn = d_norn\n",
    "        self.margin = torch.tensor([margin]).to(self.device)\n",
    "\n",
    "        self.ent_emb =  nn.Embedding.from_pretrained(\n",
    "            torch.empty(ent_num, self.dim).uniform_(-6 / math.sqrt(self.dim), 6 / math.sqrt(self.dim)),freeze=False\n",
    "        )\n",
    "\n",
    "        self.rel_emb = nn.Embedding.from_pretrained(\n",
    "            torch.empty(rel_num, self.dim).uniform_(-6 / math.sqrt(self.dim), 6 / math.sqrt(self.dim))\n",
    "            ,freeze=False\n",
    "        )\n",
    "\n",
    "        rel_norm = torch.norm(self.rel_emb.weight.data, dim=1, keepdim=True)\n",
    "        self.rel_emb.weight.data = self.rel_emb.weight.data / rel_norm\n",
    "\n",
    "    def forward(self, pos_head, pos_relation, pos_tail, neg_head, neg_relation, neg_tail):\n",
    "        '''\n",
    "        :param pos_head: [batch_size]\n",
    "        :param pos_relation: [batch_size]\n",
    "        :param pos_tail: [batch_size]\n",
    "        :param neg_head: [batch_size]\n",
    "        :param neg_relation: [batch_size]\n",
    "        :param neg_tail: [batch_size]\n",
    "        :return: triple_loss\n",
    "        '''\n",
    "\n",
    "        pos_dis = self.ent_emb(pos_head) + self.rel_emb(pos_relation) - self.ent_emb(pos_tail)\n",
    "\n",
    "        neg_dis = self.ent_emb(neg_head) + self.rel_emb(neg_relation) - self.ent_emb(neg_tail)\n",
    "\n",
    "        # return pos_head_and_relation, pos_tail, neg_head_and_relation, neg_tail\n",
    "\n",
    "        return self.calculate_loss(pos_dis, neg_dis).requires_grad_()\n",
    "\n",
    "    def calculate_loss(self, pos_dis, neg_dis):\n",
    "        '''\n",
    "        :param pos_dis: [batch_size, embed_dim]\n",
    "        :param neg_dis: [batch_size, embed_dim]\n",
    "        :return: triples loss: [batch_size]\n",
    "        '''\n",
    "\n",
    "        distance_diff = self.margin + torch.norm(pos_dis, p=self.d_norn, dim=1) - \\\n",
    "                        torch.norm(neg_dis, p=self.d_norn, dim=1)\n",
    "\n",
    "        return torch.sum(F.relu(distance_diff))\n",
    "\n",
    "    def tail_predict(self, head, relation, tail, k=10):\n",
    "        '''\n",
    "        to do tail prediction hits@k\n",
    "        :param head: [batch_size]\n",
    "        :param relation: [batch_size]\n",
    "        :param tail: [batch_size]\n",
    "        :param k: hits@k\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        # head: [batch_size]\n",
    "        # h_and_r: [batch_size, embed_size] => [batch_size, 1, embed_size] => [batch_size, N, embed_size]\n",
    "\n",
    "        h_and_r = self.ent_emb(head) + self.rel_emb(relation)\n",
    "        h_and_r = torch.unsqueeze(h_and_r, dim=1)\n",
    "        h_and_r = h_and_r.expand(h_and_r.shape[0], self.ent_num, self.dim)\n",
    "\n",
    "        # embed_tail: [batch_size, N, embed_size]\n",
    "        embed_tail = self.ent_emb.weight.data.expand(h_and_r.shape[0], self.ent_num, self.dim)\n",
    "\n",
    "        # indices: [batch_size, k]\n",
    "        values, indices = torch.topk(torch.norm(h_and_r - embed_tail, dim=2), k, dim=1, largest=False)\n",
    "        # tail: [batch_size] => [batch_size, 1]\n",
    "        tail = tail.view(-1, 1)\n",
    "        return torch.sum(torch.eq(indices, tail)).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-15T12:42:03.952162Z",
     "end_time": "2024-03-15T12:42:03.961223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 59071 triplets\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 55\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m===>epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, test accuracy \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcorrct_test\u001B[38;5;241m/\u001B[39mtest_dataset\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__len__\u001B[39m()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 55\u001B[0m     main()\n",
      "Cell \u001B[0;32mIn[11], line 39\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# neg_head, neg_relation, neg_tail: [batch_size]\u001B[39;00m\n\u001B[1;32m     38\u001B[0m neg_head, neg_relation, neg_tail \u001B[38;5;241m=\u001B[39m neg[\u001B[38;5;241m0\u001B[39m], neg[\u001B[38;5;241m1\u001B[39m], neg[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m---> 39\u001B[0m loss \u001B[38;5;241m=\u001B[39m transe(pos_head, pos_relation, pos_tail, neg_head, neg_relation, neg_tail)\n\u001B[1;32m     40\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     41\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/anaconda3/envs/Ubuntu/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/Ubuntu/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 44\u001B[0m, in \u001B[0;36mTransE.forward\u001B[0;34m(self, pos_head, pos_relation, pos_tail, neg_head, neg_relation, neg_tail)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, pos_head, pos_relation, pos_tail, neg_head, neg_relation, neg_tail):\n\u001B[1;32m     34\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03m    :param pos_head: [batch_size]\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m    :param pos_relation: [batch_size]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    :return: triple_loss\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m---> 44\u001B[0m     pos_dis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ment_emb(pos_head) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrel_emb(pos_relation) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ment_emb(pos_tail)\n\u001B[1;32m     46\u001B[0m     neg_dis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ment_emb(neg_head) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrel_emb(neg_relation) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ment_emb(neg_tail)\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;66;03m# return pos_head_and_relation, pos_tail, neg_head_and_relation, neg_tail\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Ubuntu/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/Ubuntu/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Ubuntu/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39membedding(\n\u001B[0;32m--> 163\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_norm,\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_type, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_grad_by_freq, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparse)\n",
      "File \u001B[0;32m~/anaconda3/envs/Ubuntu/lib/python3.11/site-packages/torch/nn/modules/module.py:1682\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1673\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;66;03m# On the return type:\u001B[39;00m\n\u001B[1;32m   1676\u001B[0m \u001B[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001B[39;00m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1680\u001B[0m \u001B[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001B[39;00m\n\u001B[1;32m   1681\u001B[0m \u001B[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001B[39;00m\n\u001B[0;32m-> 1682\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m   1683\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[1;32m   1684\u001B[0m         _parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda')\n",
    "embed_dim = 50\n",
    "num_epochs = 50\n",
    "train_batch_size = 32\n",
    "test_batch_size = 256\n",
    "lr = 1e-2\n",
    "momentum = 0\n",
    "gamma = 1\n",
    "d_norm = 2\n",
    "top_k = 10\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_dataset = TrainSet()\n",
    "    test_dataset = TestSet()\n",
    "    test_dataset.convert_word_to_index(train_dataset.entity_to_index, train_dataset.relation_to_index,\n",
    "                                       test_dataset.raw_data)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "    transe = TransE(train_dataset.entity_num, train_dataset.relation_num, device, dim=embed_dim, d_norn=d_norm, margin=gamma).to(device)\n",
    "    optimizer = optim.SGD(transe.parameters(), lr=lr, momentum=momentum)\n",
    "    for epoch in range(num_epochs):\n",
    "        # e <= e / ||e||\n",
    "        entity_norm = torch.norm(transe.ent_emb.weight.data, dim=1, keepdim=True)\n",
    "        transe.ent_emb.weight.data = transe.ent_emb.weight.data / entity_norm\n",
    "        total_loss = 0\n",
    "        for batch_idx, (pos, neg) in enumerate(train_loader):\n",
    "            pos, neg = pos.to(device), neg.to(device)\n",
    "            # pos: [batch_size, 3] => [3, batch_size]\n",
    "            pos = torch.transpose(pos, 0, 1)\n",
    "            # pos_head, pos_relation, pos_tail: [batch_size]\n",
    "            pos_head, pos_relation, pos_tail = pos[0], pos[1], pos[2]\n",
    "            neg = torch.transpose(neg, 0, 1)\n",
    "            # neg_head, neg_relation, neg_tail: [batch_size]\n",
    "            neg_head, neg_relation, neg_tail = neg[0], neg[1], neg[2]\n",
    "            loss = transe(pos_head, pos_relation, pos_tail, neg_head, neg_relation, neg_tail)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch {epoch+1}, loss = {total_loss/train_dataset.__len__()}\")\n",
    "        corrct_test = 0\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            # data: [batch_size, 3] => [3, batch_size]\n",
    "            data = torch.transpose(data, 0, 1)\n",
    "            corrct_test += transe.tail_predict(data[0], data[1], data[2], k=top_k)\n",
    "        print(f\"===>epoch {epoch+1}, test accuracy {corrct_test/test_dataset.__len__()}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T21:54:19.564276Z",
     "end_time": "2024-03-14T22:28:27.806037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
